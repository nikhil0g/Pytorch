{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd7bc329",
   "metadata": {},
   "source": [
    "# Load and run model predictions\n",
    "## Load the model\n",
    "### In this unit we will look at how to load a model along with it's persisted parameter states and \n",
    "### inference model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7763575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.10.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "     |████████████████████████████████| 4.9 MB 552 kB/s            \n",
      "\u001b[?25hRequirement already satisfied: protobuf in /home/nikhil/anaconda3/envs/deepl/lib/python3.6/site-packages (from onnxruntime) (3.17.3)\n",
      "Requirement already satisfied: flatbuffers in /home/nikhil/anaconda3/envs/deepl/lib/python3.6/site-packages (from onnxruntime) (1.12)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/nikhil/anaconda3/envs/deepl/lib/python3.6/site-packages (from onnxruntime) (1.19.5)\n",
      "Requirement already satisfied: six>=1.9 in /home/nikhil/anaconda3/envs/deepl/lib/python3.6/site-packages (from protobuf->onnxruntime) (1.15.0)\n",
      "Installing collected packages: onnxruntime\n",
      "Successfully installed onnxruntime-1.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ffca257",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import onnxruntime\n",
    "from torch import nn\n",
    "import torch.onnx as onnx\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873b99d2",
   "metadata": {},
   "source": [
    "### To load the model, we will define the model class which contains the state and parameters of the neural\n",
    "### network used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "346a1048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc7dd5",
   "metadata": {},
   "source": [
    "### When loading model weights, we needed to instantiate the model class first, because the class defines\n",
    "### the structure of a network. Next, we load the parameters using the load_state_dict() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7cc815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load('data/model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3675eb1",
   "metadata": {},
   "source": [
    "# Model Inference\n",
    "### Optimizing a models to run on a variety of platforms and programming languages is difficult.\n",
    "### It's very time consuming to maximize performance across all the different combinations of frameworks \n",
    "### and hardware. The Open Neural Network Exchange (ONNX) runtime provides a solution for you to train once \n",
    "### and acelerate inference on any hardward, cloud or edge devices is needed.\n",
    "\n",
    "### ONNX is a common format supported by a number of vendors to share neural networks and other machine \n",
    "### learning models. You can use ONNX format to do inference on your model on other programming languages \n",
    "### and frameworks such as Java, JavaScript, C# and ML.NET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed7836d",
   "metadata": {},
   "source": [
    "# Exporting the model to ONNX\n",
    "### PyTorch also has native ONNX export support. Given the dynamic nature of the PyTorch execution graph, \n",
    "### however, the export process must traverse the execution graph to produce a persisted ONNX model. \n",
    "### For this reason, a test variable of the appropriate size should be passed in to the export routine \n",
    "### (in our case, we will create a dummy zero tensor of the correct size. You can get the size from the \n",
    "### shape fuction on your training dataset. e.g tensor.shape):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02757680",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.zeros((1,28,28))\n",
    "onnx_model = 'data/model.onnx'\n",
    "onnx.export(model, input_image, onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc9650",
   "metadata": {},
   "source": [
    "### We will use our test dataset as sample data for inference from the ONNX model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4be1f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "x, y = test_data[0][0], test_data[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6dfb9",
   "metadata": {},
   "source": [
    "### We need to create inference session with onnxruntime.InferenceSession. To inference the onnx model,\n",
    "### use run and pass in the list of outputs you want returned (leave empty if you want all of them) and a\n",
    "### map of the input values. The result is a list of the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df5ee025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "session = onnxruntime.InferenceSession(onnx_model, None)\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "result = session.run([output_name], {input_name: x.numpy()})\n",
    "predicted, actual = classes[result[0][0].argmax(0)], classes[y]\n",
    "print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b54ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
