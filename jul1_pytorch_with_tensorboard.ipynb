{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d9e4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Step 100/938, Loss 0.5984\n",
      "Epoch 1/1, Step 200/938, Loss 0.3532\n",
      "Epoch 1/1, Step 300/938, Loss 0.1747\n",
      "Epoch 1/1, Step 400/938, Loss 0.1709\n",
      "Epoch 1/1, Step 500/938, Loss 0.1454\n",
      "Epoch 1/1, Step 600/938, Loss 0.1726\n",
      "Epoch 1/1, Step 700/938, Loss 0.2763\n",
      "Epoch 1/1, Step 800/938, Loss 0.1220\n",
      "Epoch 1/1, Step 900/938, Loss 0.1584\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 64 but got size 16 for tensor number 156 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11551/3318080379.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 64 but got size 16 for tensor number 156 in the list."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/mnist')\n",
    "\n",
    "#device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyprparameters\n",
    "input_size = 784   #28*28\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "#MNIST datasets\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                          train=True,\n",
    "                                          transform=transforms.ToTensor(),\n",
    "                                          download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                         train=False,\n",
    "                                         transform=transforms.ToTensor())\n",
    "\n",
    "#data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "example = iter(test_loader)\n",
    "example_data, example_targets = example.next()\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "#plt.show()\n",
    "img_grid = torchvision.utils.make_grid(example_data)\n",
    "writer.add_image('minist_images', img_grid)\n",
    "writer.close()\n",
    "#sys.exit()\n",
    "\n",
    "#fully connected nn with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "            #no activation and softmax function at the end\n",
    "        return out\n",
    "        \n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "#loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "writer.add_graph(model, example_data.reshape(-1, 28*28))\n",
    "\n",
    "#train the model\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "running_loss = 0.0\n",
    "running_correct = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        #orign shape [100, 1, 28, 28]\n",
    "        #resized [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Step {i+1}/{n_total_steps}, Loss {loss.item():.4f}')\n",
    "            writer.add_scalar('traning loss ',running_loss / 100, epoch * n_total_steps * i)\n",
    "            writer.add_scalar('Accuracy ',running_correct / 100, epoch * n_total_steps * i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "            \n",
    "#test the model\n",
    "#In test phase we dont need to compute gradients\n",
    "labels = []\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels1 in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels1 = labels1.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value , index\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels1.size(0)\n",
    "        n_correct += (predicted == labels1).sum().item()\n",
    "        \n",
    "        class_predictions = [F.softmax(outputs, dim=0) for output in outputs]\n",
    "        \n",
    "        preds.append(class_predictions)\n",
    "        labels.append(predicted)\n",
    "    \n",
    "    preds = torch.cat([torch.stack(batch) for batch in preds])\n",
    "    labels = torch.cat(labels)    \n",
    "        \n",
    "acc = 100.0 * n_correct / n_samples\n",
    "print(f'Accuracy of the network on the test images: {acc}%')\n",
    "\n",
    "classes = range(10)\n",
    "for i in classes:\n",
    "    label_i = labels == i\n",
    "    preds_i = pred[:, i]\n",
    "    writer.add_pr_curve(str(i), label_i, preds_i, global_step=0)\n",
    "    writer.close()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5695740d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-02 12:41:35.290051: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-02 12:41:35.290078: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-07-02 12:41:36.915495: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-02 12:41:36.915527: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-02 12:41:36.915545: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nikserver): /proc/driver/nvidia/version does not exist\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.9.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir runs/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46944228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
